---
title: "Midterm Project Analysis"
author: "Zhezheng Jin"
output:
  pdf_document:
    latex_engine: xelatex
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
header-includes:
- \usepackage{fancyhdr}
- \usepackage{lipsum}
- \pagestyle{fancy}
- \fancyhead[R]{\thepage}
- \fancypagestyle{plain}{\pagestyle{fancy}}
editor_options: 
  chunk_output_type: console
--- 

\newpage

```{r, echo = TRUE, message = FALSE, results='hide', warning=FALSE}
library(tidyverse)
library(caret)
library(mgcv)
library(pdp)
library(corrplot)
library(plotmo)
library(ggrepel)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Summary Statistics
```{r}
load("recovery.RData")
dat <- dat %>%
  select(-id)
summary(dat)
sum(is.na(dat))
skimr::skim(dat)
```

The "recovery" dataset contains `r ncol(dat)` columns and `r nrow(dat)` observations without any missing values after omitting the `id` variable. We have 14 predictors (11 numeric and 3 factor(character) variables) in the dataset.

## Model training Preparation
```{r}
# data partition
set.seed(5)
indexTrain <- createDataPartition(y = dat$recovery_time, p = 0.8, list = FALSE)
train <- dat[indexTrain, ]
test <- dat[-indexTrain, ]

# matrix of predictors 
x <- model.matrix(recovery_time~.,train)[,-1]
x2 <- model.matrix(recovery_time~.,test)[,-1]

# vector of response
y <- train$recovery_time
y2 <- test$recovery_time
```

## Expoloratory Data Analysis
```{r}
# Remove all the categorical predictors out from x
x_continuous <- 
  x[, !(colnames(x) %in% 
          c("gender", "race2","race3", "race4", 
            "smoking1","smoking2", "hypertension", 
            "diabetes", "vaccine", "severity", "studyB"))]
# Correlation plots
corrplot(cor(x_continuous), method = "circle", type = "full")
```

From the correlation matrix, some multicollinearities are severe shown in the numerical predictors of training data, cross-validation will be applied in the next steps.

Next, we will fit 5 linear models(Lasso, ridge, elastic net, PCR, PLS) and 2 non-linear models(GAM, MARS) using caret, and conduct the model comparison to choose the best fitted one.

## Lasso 
```{r}
# 10-fold cv on best
ctrl1 <- trainControl(method = "cv", number = 10)
# Fitting the model with Cross-validation
set.seed(5)
lasso.fit <- train(x, y, method = "glmnet", 
                   tuneGrid = expand.grid(alpha = 1,
                                          lambda = exp(seq(6, 0, length=100))),
                   trControl = ctrl1)

plot(lasso.fit, xTrans = log)

# Tuning parameters
lasso.fit$bestTune

# coefficients in the final model
coef(lasso.fit$finalModel, lasso.fit$bestTune$lambda)

# Make prediction on test data
lasso.pred <- predict(lasso.fit, newdata = x2)

# Test error
lasso.mse <- mean((lasso.pred - y2)^2)
lasso.mse
```

## Ridge
```{r}
# Fitting the model with Cross-validation
set.seed(5)
ridge.fit <- train(x, y, method = "glmnet", 
                   tuneGrid = expand.grid(alpha = 0,
                                          lambda = exp(seq(6, 0, length=100))),
                   trControl = ctrl1)

plot(ridge.fit, xTrans = log)

# Tuning parameters
ridge.fit$bestTune

# coefficients in the final model
coef(ridge.fit$finalModel, s = ridge.fit$bestTune$lambda)

# Make prediction on test data
ridge.pred <- predict(ridge.fit, newdata = x2)

# Test error
ridge.mse <- mean((ridge.pred - y2)^2)
ridge.mse
```

## Elastic net
```{r}
# Fitting the model with Cross-validation
set.seed(5)
enet.fit <- train(x, y,method = "glmnet",
                  tuneGrid = expand.grid(alpha = seq(0 , 1, length = 19), 
                                         lambda = exp(seq(6, 0, length = 100))),
                  trControl = ctrl1)

# Tuning parameters
enet.fit$bestTune

# 25 kinds of Plot colors
myCol<- rainbow(25)
myPar <- list(superpose.symbol = list(col = myCol),
superpose.line = list(col = myCol))

# Plot CV RMSE-alpha&lambda
plot(enet.fit, par.settings = myPar)

# Coefficients
coef(enet.fit$finalModel, enet.fit$bestTune$lambda)

# Make prediction on test data
enet.pred <- predict(enet.fit, newdata = x2)

# Test error
enet.mse <- mean((enet.pred - y2)^2)
enet.mse
```

## Principal Component Regression(PCR)

```{r}
# Fitting the model with Cross-validation
set.seed(5)
pcr.fit <-  train(x, y,
                  method = "pcr",
                  tuneGrid = data.frame(ncomp = 1:17),
                  trControl = ctrl1,
                  preProcess = c("center", "scale"))

# Make prediction on test data
pcr.pred <- predict(pcr.fit, newdata = x2)

# Test error
pcr.mse <- mean((pcr.pred - y2)^2)
pcr.mse

# Plot cv RMSE-components
ggplot(pcr.fit, highlight = TRUE) + theme_bw()
```


## Partial least squares(PLS)
```{r}
# Fitting the model with Cross-validation
set.seed(5)
pls.fit <-  train(x, y,
                  method = "pls",
                  tuneGrid = data.frame(ncomp = 1:17),
                  trControl = ctrl1,
                  preProcess = c("center", "scale"))

# Make prediction on test data
pls.pred <- predict(pls.fit, newdata = x2)

# Test error
pls.mse <- mean((pls.pred - y2)^2)
pls.mse

# Plot cv RMSE-components
ggplot(pls.fit, highlight = TRUE)
```

## Generalized additive model (GAM)


## Multivariate Adaptive Regression Splines (MARS)




## Model Comparison
```{r}
# resamples
set.seed(5)
resamp <- resamples(list(lasso = lasso.fit,
                         ridge = ridge.fit,
                         enet = enet.fit,
                         pcr = pcr.fit,
                         pls = pls.fit))
summary(resamp)

# RMSE box-plot between models
bwplot(resamp, metric = "RMSE")
```

Based on the summary and plot, we would likely use the () to predict our response because they minimize the mean RMSE over resamples.

